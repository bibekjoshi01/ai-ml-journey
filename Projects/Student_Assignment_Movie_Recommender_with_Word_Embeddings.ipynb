{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpBDGNJA4ejL"
   },
   "source": [
    "# Movie Recommender using Word Embeddings\n",
    "## Learning Objective\n",
    "Here in this assignment, you will train word embeddings using gensim. Then you will use the learnt embeddings to a movie recommender application.\n",
    "\n",
    "<b><div style=\"text-align: right\">[TOTAL POINTS: 20]</div></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkGYuiTK4sib"
   },
   "source": [
    "## Assignment Overview\n",
    "\n",
    "In this assignment, you will demonstrate the application of word embeddings for movie recommendation. You will pre-process the dataset and extract the useful columns from the dataset (containing description or information about the movie in text format). Then you will estimate the word embeddings of the words in the description using [gensim](https://) library. You will average the word embeddings of the description and based on the cosine similarity between the similar description, you will build a movie recommender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bcG5bRyBQZC"
   },
   "source": [
    "## Dataset Description\n",
    "\n",
    "In this assignment, you will use [The Movies Dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset?select=movies_metadata.csv). The dataset contains metadata for 45,000 movies listed in the Full MovieLens Dataset. The dataset consists of movies released on or before July 2017.\n",
    "\n",
    "This dataset consists of the following files:\n",
    "\n",
    "movies_metadata.csv: This is the main Movies Metadata file. It contains information about 45,000 movies featured in the Full MovieLens dataset.\n",
    "The features of the `movies_metadata.csv` include:\n",
    "* genres\n",
    "* overview\n",
    "* tagline\n",
    "* posters\n",
    "* backdrops\n",
    "* budget\n",
    "* review\n",
    "* release dates\n",
    "* languages\n",
    "* production countries\n",
    "* production companies\n",
    "\n",
    "keywords.csv: Contains the movie plot keywords for MovieLens movies.\n",
    "\n",
    "credits.csv: Consists of Cast and Crew Information for the movies.\n",
    "\n",
    "links.csv: The file that contains the TMDB and IMDB IDs of all the movies featured in the Full MovieLens dataset.\n",
    "\n",
    "links_small.csv: Contains the TMDB and IMDB IDs of a small subset of 9,000 movies of the Full Dataset.\n",
    "\n",
    "ratings_small.csv: The subset of 100,000 ratings from 700 users on 9,000 movies.\n",
    "\n",
    "\\\n",
    "In this programming assignment you will only use the `movies_metadata.csv` dataset.\n",
    "\n",
    "\\\n",
    "**Licence**:  [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)\n",
    "\n",
    "**Source**: https://www.kaggle.com/rounakbanik/the-movies-dataset?select=movies_metadata.csv \\\n",
    "**Number of instances**: 45466\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[53 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[36m\u001b[1m+ meson setup /private/var/folders/jp/_n1yy6w143x6rxr2gt1kr6d00000gn/T/pip-install-i_d7bht3/scipy_0a56b9631e6b46a29c4ad4fb729c098e /private/var/folders/jp/_n1yy6w143x6rxr2gt1kr6d00000gn/T/pip-install-i_d7bht3/scipy_0a56b9631e6b46a29c4ad4fb729c098e/.mesonpy-hc8pmblp -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/jp/_n1yy6w143x6rxr2gt1kr6d00000gn/T/pip-install-i_d7bht3/scipy_0a56b9631e6b46a29c4ad4fb729c098e/.mesonpy-hc8pmblp/meson-python-native-file.ini\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The Meson build system\n",
      "  \u001b[31m   \u001b[0m Version: 1.9.0\n",
      "  \u001b[31m   \u001b[0m Source dir: /private/var/folders/jp/_n1yy6w143x6rxr2gt1kr6d00000gn/T/pip-install-i_d7bht3/scipy_0a56b9631e6b46a29c4ad4fb729c098e\n",
      "  \u001b[31m   \u001b[0m Build dir: /private/var/folders/jp/_n1yy6w143x6rxr2gt1kr6d00000gn/T/pip-install-i_d7bht3/scipy_0a56b9631e6b46a29c4ad4fb729c098e/.mesonpy-hc8pmblp\n",
      "  \u001b[31m   \u001b[0m Build type: native build\n",
      "  \u001b[31m   \u001b[0m Project name: scipy\n",
      "  \u001b[31m   \u001b[0m Project version: 1.13.1\n",
      "  \u001b[31m   \u001b[0m C compiler for the host machine: cc (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.5)\")\n",
      "  \u001b[31m   \u001b[0m C linker for the host machine: cc ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m C++ compiler for the host machine: c++ (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.5)\")\n",
      "  \u001b[31m   \u001b[0m C++ linker for the host machine: c++ ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m Cython compiler for the host machine: cython (cython 3.0.12)\n",
      "  \u001b[31m   \u001b[0m Host machine cpu family: aarch64\n",
      "  \u001b[31m   \u001b[0m Host machine cpu: aarch64\n",
      "  \u001b[31m   \u001b[0m Program python found: YES (/Users/bibekjoshi01/Drive X/my-projects/ai-ml-journey/.venv/bin/python3.13)\n",
      "  \u001b[31m   \u001b[0m Found pkg-config: YES (/opt/homebrew/bin/pkg-config) 2.4.3\n",
      "  \u001b[31m   \u001b[0m Run-time dependency python found: YES 3.13\n",
      "  \u001b[31m   \u001b[0m Program cython found: YES (/private/var/folders/jp/_n1yy6w143x6rxr2gt1kr6d00000gn/T/pip-build-env-zt3sq95m/overlay/bin/cython)\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-but-set-variable: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-function: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-conversion: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-misleading-indentation: YES\n",
      "  \u001b[31m   \u001b[0m Library m found: YES\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ../meson.build:78:0: ERROR: Unknown compiler(s): [['gfortran'], ['flang-new'], ['flang'], ['nvfortran'], ['pgfortran'], ['ifort'], ['ifx'], ['g95']]\n",
      "  \u001b[31m   \u001b[0m The following exception(s) were encountered:\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --help` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --version` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran -V` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --help` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --version` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new -V` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --help` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --version` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang -V` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --help` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --version` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran -V` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --help` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --version` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran -V` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --help` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --version` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort -V` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --help` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --version` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx -V` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --help` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --version` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 -V` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m A full log can be found at /private/var/folders/jp/_n1yy6w143x6rxr2gt1kr6d00000gn/T/pip-install-i_d7bht3/scipy_0a56b9631e6b46a29c4ad4fb729c098e/.mesonpy-hc8pmblp/meson-logs/meson-log.txt\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gensim\n",
    "!pip install -q scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RuLGzL9RpO61"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0z4iteXpcBh"
   },
   "source": [
    "Let's quickly look at the portion of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "coFYaAHf4tXO",
    "outputId": "9e192a05-1429-43a3-9f26-29ab5d58823e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('movies_metadata.csv')\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RxNLJgyFvzqK",
    "outputId": "9cdb53e9-d92a-4df9-b615-a16d24a3ebb5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           keywords\n",
       "0    862  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...\n",
       "1   8844  [{'id': 10090, 'name': 'board game'}, {'id': 1...\n",
       "2  15602  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...\n",
       "3  31357  [{'id': 818, 'name': 'based on novel'}, {'id':...\n",
       "4  11862  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('keywords.csv')\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlMEkgB3vzqL"
   },
   "source": [
    "There are some id's which contains date as the id number. Let's delete those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SS3w37ZrvzqL",
    "outputId": "02dc5697-1317-477e-d998-3e00885079e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19730</th>\n",
       "      <td>- Written by Ørnås</td>\n",
       "      <td>0.065736</td>\n",
       "      <td>/ff9qCepilowshEtG2GYWwzt2bs4.jpg</td>\n",
       "      <td>[{'name': 'Carousel Productions', 'id': 11176}...</td>\n",
       "      <td>[{'iso_3166_1': 'CA', 'name': 'Canada'}, {'iso...</td>\n",
       "      <td>1997-08-20</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29503</th>\n",
       "      <td>Rune Balot goes to a casino connected to the ...</td>\n",
       "      <td>1.931659</td>\n",
       "      <td>/zV8bHuSL6WXoD6FWogP9j4x80bL.jpg</td>\n",
       "      <td>[{'name': 'Aniplex', 'id': 2883}, {'name': 'Go...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>2012-09-29</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>[{'iso_639_1': 'ja', 'name': '日本語'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35587</th>\n",
       "      <td>Avalanche Sharks tells the story of a bikini ...</td>\n",
       "      <td>2.185485</td>\n",
       "      <td>/zaSf5OG7V8X8gqFvly88zDdRm46.jpg</td>\n",
       "      <td>[{'name': 'Odyssey Media', 'id': 17161}, {'nam...</td>\n",
       "      <td>[{'iso_3166_1': 'CA', 'name': 'Canada'}]</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   adult  \\\n",
       "19730                                 - Written by Ørnås   \n",
       "29503   Rune Balot goes to a casino connected to the ...   \n",
       "35587   Avalanche Sharks tells the story of a bikini ...   \n",
       "\n",
       "      belongs_to_collection                            budget  \\\n",
       "19730              0.065736  /ff9qCepilowshEtG2GYWwzt2bs4.jpg   \n",
       "29503              1.931659  /zV8bHuSL6WXoD6FWogP9j4x80bL.jpg   \n",
       "35587              2.185485  /zaSf5OG7V8X8gqFvly88zDdRm46.jpg   \n",
       "\n",
       "                                                  genres  \\\n",
       "19730  [{'name': 'Carousel Productions', 'id': 11176}...   \n",
       "29503  [{'name': 'Aniplex', 'id': 2883}, {'name': 'Go...   \n",
       "35587  [{'name': 'Odyssey Media', 'id': 17161}, {'nam...   \n",
       "\n",
       "                                                homepage          id imdb_id  \\\n",
       "19730  [{'iso_3166_1': 'CA', 'name': 'Canada'}, {'iso...  1997-08-20       0   \n",
       "29503  [{'iso_3166_1': 'US', 'name': 'United States o...  2012-09-29       0   \n",
       "35587           [{'iso_3166_1': 'CA', 'name': 'Canada'}]  2014-01-01       0   \n",
       "\n",
       "      original_language                            original_title  overview  \\\n",
       "19730             104.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "29503              68.0      [{'iso_639_1': 'ja', 'name': '日本語'}]  Released   \n",
       "35587              82.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "       ... release_date revenue runtime spoken_languages status  tagline  \\\n",
       "19730  ...            1     NaN     NaN              NaN    NaN      NaN   \n",
       "29503  ...           12     NaN     NaN              NaN    NaN      NaN   \n",
       "35587  ...           22     NaN     NaN              NaN    NaN      NaN   \n",
       "\n",
       "       title video vote_average vote_count  \n",
       "19730    NaN   NaN          NaN        NaN  \n",
       "29503    NaN   NaN          NaN        NaN  \n",
       "35587    NaN   NaN          NaN        NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1.id.str.contains('\\d{4}-\\d{2}-\\d{2}', regex= True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4HhZ0uRUvzqL"
   },
   "outputs": [],
   "source": [
    "df1 = df1.drop([19730, 29503, 35587])\n",
    "df2 = df2.drop([19730, 29503, 35587])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fo01bNd7vzqM"
   },
   "source": [
    "Let's change the datatype of id column to be int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_R4RmJcYvzqM"
   },
   "outputs": [],
   "source": [
    "df1['id'] = df1['id'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9SVJJQSvzqM"
   },
   "source": [
    "Let's merge two dataframes on id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tuijcxWMvzqM",
    "outputId": "39aa4e88-f25d-4a03-917f-2c078a08d93e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  ...      revenue  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...  373554033.0   \n",
       "1  When siblings Judy and Peter discover an encha...  ...  262797249.0   \n",
       "2  A family wedding reignites the ancient feud be...  ...          0.0   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   81452156.0   \n",
       "4  Just when George Banks has recovered from his ...  ...   76578911.0   \n",
       "\n",
       "  runtime                                   spoken_languages    status  \\\n",
       "0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "2   101.0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "3   127.0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "4   106.0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "                                             tagline  \\\n",
       "0                                                NaN   \n",
       "1          Roll the dice and unleash the excitement!   \n",
       "2  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Friends are the people who let you be yourself...   \n",
       "4  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \\\n",
       "0                    Toy Story  False          7.7     5415.0   \n",
       "1                      Jumanji  False          6.9     2413.0   \n",
       "2             Grumpier Old Men  False          6.5       92.0   \n",
       "3            Waiting to Exhale  False          6.1       34.0   \n",
       "4  Father of the Bride Part II  False          5.7      173.0   \n",
       "\n",
       "                                            keywords  \n",
       "0  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...  \n",
       "1  [{'id': 10090, 'name': 'board game'}, {'id': 1...  \n",
       "2  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...  \n",
       "3  [{'id': 818, 'name': 'based on novel'}, {'id':...  \n",
       "4  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df1.merge(df2,on='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xt3CR9fph9z"
   },
   "source": [
    "Let's remove the following columns from the dataset. These columns are either numeric or not providing much information about the description of the movie as texts.\n",
    "\n",
    "adult: containing information about the movie is \"adult\" or not.\n",
    "\n",
    "belongs_to_collection: contating information about the collection type \n",
    "\n",
    "budget: the budget of the movie\n",
    "\n",
    "homepage: original homepage of the move\n",
    "\n",
    "imdb_id: the imdb id of the movie\n",
    "\n",
    "id: the unique identifier of the movie\n",
    "\n",
    "original_title: the original title of the movie\n",
    "\n",
    "release_date: the releasing date of the movie\n",
    "\n",
    "poster_path: the path containing image of the movie\n",
    "\n",
    "production_countries: the production countries of the movie\n",
    "\n",
    "revenue: the revenue of the movie\n",
    "\n",
    "runtime: the runtime of the movie\n",
    "\n",
    "spoken_languages: the spoken languages of the movie\n",
    "\n",
    "status: the status of the movie\n",
    "\n",
    "video: either the movie has video or not\n",
    "\n",
    "vote_average: the vote average of the movie\n",
    "\n",
    "vote_count: the vote count of the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "gdWrACr84tXR",
    "outputId": "2d602dc5-30d6-478b-b895-33b9cc54dda4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>en</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>[{'name': 'Pixar Animation Studios', 'id': 3}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>en</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>[{'name': 'TriStar Pictures', 'id': 559}, {'na...</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>en</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>[{'name': 'Warner Bros.', 'id': 6194}, {'name'...</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>en</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>[{'name': 'Twentieth Century Fox Film Corporat...</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>en</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>[{'name': 'Sandollar Productions', 'id': 5842}...</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              genres original_language  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...                en   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...                en   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...                en   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...                en   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]                en   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   \n",
       "4  Just when George Banks has recovered from his ...   \n",
       "\n",
       "                                production_companies  \\\n",
       "0     [{'name': 'Pixar Animation Studios', 'id': 3}]   \n",
       "1  [{'name': 'TriStar Pictures', 'id': 559}, {'na...   \n",
       "2  [{'name': 'Warner Bros.', 'id': 6194}, {'name'...   \n",
       "3  [{'name': 'Twentieth Century Fox Film Corporat...   \n",
       "4  [{'name': 'Sandollar Productions', 'id': 5842}...   \n",
       "\n",
       "                                             tagline  \\\n",
       "0                                                NaN   \n",
       "1          Roll the dice and unleash the excitement!   \n",
       "2  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Friends are the people who let you be yourself...   \n",
       "4  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            keywords  \n",
       "0  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...  \n",
       "1  [{'id': 10090, 'name': 'board game'}, {'id': 1...  \n",
       "2  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...  \n",
       "3  [{'id': 818, 'name': 'based on novel'}, {'id':...  \n",
       "4  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['adult', 'belongs_to_collection','budget', \n",
    "              'homepage', 'imdb_id', 'id', 'original_title',\n",
    "              'release_date', 'poster_path', 'production_countries',\n",
    "              'popularity','revenue','runtime', 'spoken_languages', \n",
    "              'status', 'video','vote_average', 'vote_count'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUJIriWUvE9D"
   },
   "source": [
    "### Exercise 1 : Concat Description\n",
    "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
    "\n",
    "You can now see that there are following columns in the dataset.\n",
    "\n",
    "title: the movie name or the title of the movie \n",
    "\n",
    "keywords: keyword for the movie\n",
    "\n",
    "genres: the genre of the movie\n",
    "\n",
    "original_language: original language of the movie\n",
    "\n",
    "overview: the overview(description) of the movie\n",
    "\n",
    "production companies: the production companies of the movie\n",
    "\n",
    "tagline: the brief description of the movie\n",
    "\n",
    "Your task is to concat all of these descriptions of the movies as a single description as a string.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "* concat all of these descriptions of the movies as a single description as a string in the variable `df['concat_description']`.\n",
    "\n",
    "* Concatination should follow the following format:\\\n",
    "`keywords + space + genres + space + original_language + space + production_companies + space + tagline + space + overview`\\\n",
    "`Note: Don't forget to typecast to string format.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "id": "53Lt_v-G4tXV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4ff43ff2bea613dec9d95fb1a401dce",
     "grade": false,
     "grade_id": "cell-ce872bf2cb98e0fc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-1-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "df['concat_description'] = None\n",
    "### Ex-1-Task-1\n",
    "### BEGIN SOLUTION \n",
    "df['concat_description'] = (\n",
    "    df['keywords'].astype(str) + \" \" +\n",
    "    df['genres'].astype(str) + \" \" +\n",
    "    df['original_language'].astype(str) + \" \" +\n",
    "    df['production_companies'].astype(str) + \" \" +\n",
    "    df['tagline'].astype(str) + \" \" +\n",
    "    df['overview'].astype(str)\n",
    ")\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "jmvKbwl5vzqN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca490618ca8e9955369e80900cea701d",
     "grade": true,
     "grade_id": "cell-f9d22533930f18e1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-1-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "oa92zZxi4tXY",
    "outputId": "073b290a-f56c-4c04-9277-db627aebf22a"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['concat_description'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconcat_description\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      2\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Drive X/my-projects/ai-ml-journey/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Drive X/my-projects/ai-ml-journey/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Drive X/my-projects/ai-ml-journey/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['concat_description'] not in index\""
     ]
    }
   ],
   "source": [
    "df = df[['title', 'concat_description']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiuiI5RFOtTL"
   },
   "source": [
    "### Exercise 2 : Preprocessing Dataset\n",
    "<b><div style=\"text-align: right\">[POINTS: 5]</div></b>\n",
    "\n",
    "Now that you have title and concatenated descriptions of all of the movies. Your task is to lowecase the text of descriptions, to remove the stop words, to remove blacklisted words such as **id, name and nan**, to remove numbers and finally to remove punctuations from the `concat_description`.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "* lowercase the description\n",
    "* remove the stop words\n",
    "* remove punctuations such as \"{\", \".\", \"?\", \":\" etc.\\\n",
    "`Hint: Use nltk.tokenize.RegexpTokenizer()`\n",
    "* remove blacklist words (\"id\", \"name\", and \"nan\")\n",
    "* remove numbers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fx9H_q7K4tXb",
    "outputId": "cc439e03-b68a-4b1b-a8ec-5c6f8351f7cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.71 ms, sys: 2.48 ms, total: 4.19 ms\n",
      "Wall time: 3.35 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bibekjoshi01/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "id": "TspAXEJWvzqO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "222bf48c63fa174ff70e309b168b1c79",
     "grade": false,
     "grade_id": "cell-00764f245cf20092",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-2-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "def make_lower_case(text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        text (str): a string\n",
    "    Returns:\n",
    "        text_lower (str):  a lowecased string\n",
    "    \"\"\"\n",
    "    text_lower = None\n",
    "    ### Ex-2-Task-1\n",
    "    ### BEGIN SOLUTION \n",
    "    text_lower = str(text).lower()\n",
    "    ### END SOLUTION\n",
    "    return text_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cGsvRqZAvzqO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afa3de69ae0a21684aedf25a708b43d1",
     "grade": true,
     "grade_id": "cell-f8bbf9c4eb2d65f4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-2-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "id": "9W4DNTyHvzqO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00357715053b09e3f8e0e3c26230392a",
     "grade": false,
     "grade_id": "cell-a23f3315e768017b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-2-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        text (str): a string\n",
    "    Returns:\n",
    "        removed_stop_word_text (str):  string with removed stop words in the text\n",
    "    \"\"\"\n",
    "    text = text.split()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    removed_stop_word_text = None\n",
    "    ### Ex-2-Task-2\n",
    "    ### BEGIN SOLUTION \n",
    "    filtered_tokens = [word for word in text if word not in stop_words]\n",
    "    removed_stop_word_text = \" \".join(filtered_tokens)\n",
    "    ### END SOLUTION\n",
    "    return removed_stop_word_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0dX2Rwt4vzqO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e9206ad0e27243159f6ce4ac91c2276",
     "grade": true,
     "grade_id": "cell-a22a9f5c8f14f5c2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-2-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "id": "RH9maFzsvzqO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4de0979c541b4ba0c95422cc05660838",
     "grade": false,
     "grade_id": "cell-25eaba46d4f7c1b4",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-2-Task-3"
    ]
   },
   "outputs": [],
   "source": [
    "def remove_blacklist_words(text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        text (str): a string\n",
    "    Returns:\n",
    "        removed_stop_word_text (str):  string with removed black listed words in the text\n",
    "    \"\"\"\n",
    "    text = text.split()\n",
    "    black_list = [\"id\", \"name\", \"nan\"]\n",
    "    removed_black_list_text = None\n",
    "    ### Ex-2-Task-3\n",
    "    ### BEGIN SOLUTION \n",
    "    filtered_tokens = [word for word in text if word not in black_list]\n",
    "    removed_black_list_text = \" \".join(filtered_tokens)\n",
    "    ### END SOLUTION\n",
    "    return removed_black_list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "LFPTSvhovzqO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "093ee00ed3bc73e8b8d00a49d3dc98c7",
     "grade": true,
     "grade_id": "cell-9ce5c555a34d8747",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-2-Task-3"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "id": "AOIUAFSrvzqO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e43f2de09302c54a3a5ed9f401149c3",
     "grade": false,
     "grade_id": "cell-2ec883b4dde788d7",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-2-Task-4"
    ]
   },
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        text (str): a string\n",
    "    Returns:\n",
    "        text_lower (str):  string with removed numbers from the text.\n",
    "    \"\"\"\n",
    "    pattern = r'[0-9]'\n",
    "    ### Ex-2-Task-4\n",
    "    ### BEGIN SOLUTION \n",
    "    import re\n",
    "    removed_numbers_text = re.sub(pattern, '', str(text))\n",
    "    ### END SOLUTION\n",
    "    return removed_numbers_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vHCUcLzHvzqO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f3fb3004793d8f3a3397878fb23f41f",
     "grade": true,
     "grade_id": "cell-2d9283af5e48127b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-2-Task-4"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "id": "z0R1eHrhvzqP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe1103a405c9dbba5b4e2190f45420f6",
     "grade": false,
     "grade_id": "cell-5cf9912dba986e57",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-2-Task-5"
    ]
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        text (str): a string\n",
    "    Returns:\n",
    "        text_lower (str):  a lowecased string\n",
    "    \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    removed_punctuation_text = None\n",
    "    ### Ex-2-Task-5\n",
    "    ### BEGIN SOLUTION \n",
    "    tokens = tokenizer.tokenize(str(text))\n",
    "    removed_punctuation_text = \" \".join(tokens)\n",
    "    ### END SOLUTION\n",
    "    return removed_punctuation_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "l8BhEocCvzqP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05b46266ca5a5070f3d450438c3b2368",
     "grade": true,
     "grade_id": "cell-9176c2409b47f4d3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-2-Task-5"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "p_gNGLcMvzqP"
   },
   "outputs": [],
   "source": [
    "df['description'] = df['concat_description'].apply(make_lower_case)\n",
    "df['description'] = df.description.apply(remove_stop_words)\n",
    "df['description'] = df.description.apply(remove_punctuation)\n",
    "df['description'] = df.description.apply(remove_blacklist_words)\n",
    "df['description'] = df.description.apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6z4bTgpwKBi"
   },
   "source": [
    "Let's look at the cleaned description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "OHEeg0As4tXd",
    "outputId": "45f6e5f1-1b36-4b08-e823-5c8a677bbedc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>jealousy  toy  boy  friendship  friends  riva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>board game  disappearance  based children s b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>fishing  best friend  duringcreditsstinger  o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>based novel  interracial relationship  single...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>baby  midlife crisis  confidence  aging  daug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                         description  \n",
       "0   jealousy  toy  boy  friendship  friends  riva...  \n",
       "1   board game  disappearance  based children s b...  \n",
       "2   fishing  best friend  duringcreditsstinger  o...  \n",
       "3   based novel  interracial relationship  single...  \n",
       "4   baby  midlife crisis  confidence  aging  daug...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['concat_description'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjrLNcDLK40h",
    "outputId": "e9a6268e-cf37-4111-fffc-235ad1f568f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " jealousy  toy  boy  friendship  friends  rivalry  boy next door  new toy  toy comes life  animation  comedy  family en pixar animation studios  led woody andy s toys live happily room andy s birthday brings buzz lightyear onto scene afraid losing place andy s heart woody plots buzz circumstances separate buzz woody owner duo eventually learns put aside differences\n"
     ]
    }
   ],
   "source": [
    "print(df['description'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pv5wgSP7ecdz",
    "outputId": "ccd613f8-8705-434b-a949-d24a0e5b122f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     jealousy  toy  boy  friendship  friends  riva...\n",
       "1     board game  disappearance  based children s b...\n",
       "2     fishing  best friend  duringcreditsstinger  o...\n",
       "3     based novel  interracial relationship  single...\n",
       "4     baby  midlife crisis  confidence  aging  daug...\n",
       "5     robbery  detective  bank  obsession  chase  s...\n",
       "6     paris  brother brother relationship  chauffeu...\n",
       "7     action  adventure  drama  family en walt disn...\n",
       "8     terrorist  hostage  explosive  vice president...\n",
       "9     cuba  falsely accused  secret identity  compu...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnfdA6keRG3L"
   },
   "source": [
    "### Exercise 3: Word Embeddings with Gensim Word2Vec \n",
    "<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n",
    "\n",
    "Now that you have preprocessed the dataset, your task is to build a model for embeddings with [gensim](https://radimrehurek.com/gensim/).\n",
    "\n",
    "You will have to use the following parameters for your word2vec model.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "1. **sentences = (list) processed text in the format of list of list of words.**\n",
    "\n",
    "In your case `sentences` should be like:\n",
    "```\n",
    "[\n",
    "  ['jealousy',  'toy', 'boy', 'friendship', 'friends', .....],  # description 0\n",
    "  ['board',  'game',  'disappearance', 'based', 'children',.......],   # description 1\n",
    "  ['fishing',  'best', 'friend', 'duringcreditsstinger', ....],  # description 2\n",
    "                      ......\n",
    "                      ......\n",
    "  ['terrorist',  'hostage',  'explosive', 'vice', 'president', .....]  # description 8\n",
    "                     ......\n",
    "                     ......\n",
    "]\n",
    "```\n",
    "\n",
    "2. **sg = 1**\n",
    "\n",
    "3. **size = 300**\n",
    "\n",
    "4. **window = 10**\n",
    "\n",
    "5. **min_count = 3**\n",
    "\n",
    "6. **seed = 14**\n",
    "\n",
    "**Tasks:**\n",
    "* assign sentences to processed_text in the format of list of list of words as described in the parameter 1 in the description of the assignment.\n",
    "\n",
    "* create a Word2Vec model from gensim using the parameters described in the parameter section of the description of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46479"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [lines.split() for lines in df['description']]\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "id": "p4VmlWel4tXr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b362670892cc4986f5e8676918f59da3",
     "grade": false,
     "grade_id": "cell-858476cb2461e9d3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "a3b38328-ef24-4514-89f1-4b8b820d78da",
    "tags": [
     "Ex-3-Task-1"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m### Ex-3-Task-1\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "### Ex-3-Task-1\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "sentences = None\n",
    "model = None\n",
    "\n",
    "### BEGIN SOLUTION \n",
    "model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=300,  # previously 'size' in gensim <4.0\n",
    "    window=10,\n",
    "    min_count=3,\n",
    "    sg=1,             # skip-gram\n",
    "    seed=14\n",
    ")\n",
    "### END SOLUTION\n",
    "\n",
    "print(f\"Time for execution: {time.time() - start_time} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "i-WLHBE-vzqQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45ce076829de741ee406395b91f73e69",
     "grade": true,
     "grade_id": "cell-b9d05d16bb2e4f9b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-3-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPpbX7x8c-zi",
    "outputId": "376c2fb4-0dc0-47ff-b802-7070ba373bc7"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar('pilot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "daKyj2yYdQqn",
    "outputId": "cda80917-58b3-42d7-ed4f-e5dc06d2e263"
   },
   "outputs": [],
   "source": [
    "model.wv.most_similar('animation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4CxeK6xcTDW"
   },
   "source": [
    "### Exercise 4: Averaging Word Embeddings of all of the Words in the Description\n",
    "<b><div style=\"text-align: right\">[POINTS: 5]</div></b>\n",
    "\n",
    "Look at an example, suppose you have the following description:\n",
    "```\n",
    "jealousy  toy  boy  friendship  friends  rivalry  boy next door  new toy  toy comes ...\n",
    "```\n",
    "\n",
    "You will sum all of the word vectors in the description\n",
    "\n",
    "\n",
    "i.e.\n",
    "\n",
    "$\\text{sum_desc_vec = vec(jealousy) + vec(toy)+ vec(boy)+ vec(friendship)+ vec(friends) + vec(rivalry) + vec(boy) + vec(next) + ....}$\n",
    "\n",
    "\n",
    "Here, $\\text{vec(jealousy)}$ represents word vectors of the word **\"jealousy\"** and so on.\n",
    "\n",
    "\n",
    "Then, you will estimate the averaged vector for a description as:\n",
    "\n",
    "\n",
    "$\\text{avg_desc_vec} = \\frac{\\text{sum_desc_vec}}{\\text{number of words in the description}}$\n",
    "\n",
    "Your task is to calculate the avergae of the word vectors for all of the descriptions and store it in column named `avg_description_vector`.\n",
    "\n",
    "\n",
    "**Tasks:**\n",
    "* Get the averaged vector of all of the words in the description.\n",
    "\n",
    "**Note: you will only average the words which are in the vocab of the word embeddings i.e if the word is in `model.wv.vocab.keys()`.**\n",
    "\n",
    "Also if there are only words in the descriptions which are not in the vocab of the word embeddings, assign them to array of zeros of 300 dims. i.e (300, )\n",
    "\n",
    "**Hint:** The word embedding vectors for the word `'word'` can be accessed as `model.wv['word']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "96hnCMj3c4CB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d71559b5a3232fbd734fb49a253c3ef",
     "grade": false,
     "grade_id": "cell-08c4f62d894e9abd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "6eb14825-7a8c-4d3c-b35c-6c98c6ad19b9",
    "tags": [
     "Ex-4-Task-1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 μs, sys: 1 μs, total: 12 μs\n",
      "Wall time: 15 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "def avg_desc_vector(description):\n",
    "    \"\"\"\n",
    "    Get the average vector of each words in the description.\n",
    "\n",
    "    Args:\n",
    "        description(str): the combined description of a movie\n",
    "\n",
    "    Returns:\n",
    "        vector_sum(numpy array): Numpy array of the averaged vectors of each words in the description\n",
    "    \"\"\"\n",
    "    sum_desc_vec = 0\n",
    "    avg_desc_vec = 0\n",
    "    num_words = 0\n",
    "    words = description.split()\n",
    "    for word in words:\n",
    "        ### Ex-4-Task-1\n",
    "        ### BEGIN SOLUTION \n",
    "        if word in model.wv.key_to_index:  # check if word is in vocab (gensim >=4.0)\n",
    "            sum_desc_vec += model.wv[word]\n",
    "            num_words += 1\n",
    "        ### END SOLUTION\n",
    "\n",
    "    # If no words are in vocab, keep zeros\n",
    "    if num_words > 0:\n",
    "        avg_desc_vec = sum_desc_vec / num_words\n",
    "    else:\n",
    "        avg_desc_vec = sum_desc_vec  # already zeros\n",
    "    \n",
    "    return avg_desc_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "h1AIdk3hvzqQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06ddf1c2155962b8b9819d3ef62ae45e",
     "grade": true,
     "grade_id": "cell-42df8d811c15a848",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-4-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "id": "xcJx15AbvzqR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f75d148d7268cb7927cf72cdb1f348e2",
     "grade": false,
     "grade_id": "cell-f75a9dfa0f9b29c6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "Ex-4-Task-2"
    ]
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'concat_description_preprocessed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Drive X/my-projects/ai-ml-journey/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'concat_description_preprocessed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mavg_description_vector\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m### Ex-4-Task-2\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m### BEGIN SOLUTION \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mavg_description_vector\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconcat_description_preprocessed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.apply(avg_desc_vector)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m### END SOLUTION\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Drive X/my-projects/ai-ml-journey/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Drive X/my-projects/ai-ml-journey/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'concat_description_preprocessed'"
     ]
    }
   ],
   "source": [
    "df['avg_description_vector'] = None\n",
    "### Ex-4-Task-2\n",
    "### BEGIN SOLUTION \n",
    "df['avg_description_vector'] = df['concat_description_preprocessed'].apply(avg_desc_vector)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DocaRy5QvzqR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed70d1763fe60bcc875ab0eb8cc1cee6",
     "grade": true,
     "grade_id": "cell-e0971bbd9dcdea63",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-4-Task-2"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "pUi2BBghgs8s",
    "outputId": "e3f38140-6fe4-45c8-b9f2-5ae50a814da5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>avg_description_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>jealousy  toy  boy  friendship  friends  riva...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>board game  disappearance  based children s b...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>fishing  best friend  duringcreditsstinger  o...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>based novel  interracial relationship  single...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>baby  midlife crisis  confidence  aging  daug...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                         description avg_description_vector  \n",
       "0   jealousy  toy  boy  friendship  friends  riva...                   None  \n",
       "1   board game  disappearance  based children s b...                   None  \n",
       "2   fishing  best friend  duringcreditsstinger  o...                   None  \n",
       "3   based novel  interracial relationship  single...                   None  \n",
       "4   baby  midlife crisis  confidence  aging  daug...                   None  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xD-U0To9pXEj",
    "outputId": "3e813f14-05b8-4c5b-d08e-2d45c3db9351"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46479,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "avg_desc_vector_all = np.array(df['avg_description_vector'].to_list())\n",
    "avg_desc_vector_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tmIui3Aptos",
    "outputId": "58382db9-af68-432f-c45c-6a42153bf72c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46479,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_desc_vector_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfK7JOyOvzqR"
   },
   "source": [
    "### Exercise 5: Cosine Similarities between Movie and all of the Movies in the DataFrame\n",
    "<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n",
    "\n",
    "\n",
    "Your task is to get the cosine similarities between the given movie and all of the movies in the DataFrame.\n",
    "\n",
    "**Tasks:**\n",
    "* `movie_index`: Get the index of the movie in the DataFrame\n",
    "\n",
    "* `movie_avg_desc_vector`: Get the Description Vector of the movie\n",
    "\n",
    "* `cosine_similarities`: Get the cosine similarities between description vector of the movie and all of the descriptions (vectors) of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "id": "t3bmENiuvzqR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c01e059b6b7032599c73b2be2843563",
     "grade": false,
     "grade_id": "cell-1329c586630b01b5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-5-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def similarity_scores(movie, df=df, avg_desc_vector_all=avg_desc_vector_all):\n",
    "    \"\"\"\n",
    "    Similarity scores between movie and all of the movies in the dataframe.\n",
    "    \n",
    "    Args:\n",
    "        movie (str): Title of the Movie\n",
    "        df(DataFrame): DataFrame containing Movie title and Movie Description\n",
    "        avg_movie_vector_all(numpy array): average embeddings of all of the Movie Descriptions\n",
    "\n",
    "    Returns:\n",
    "        list: list of top 5 similar Movie title with their cosine similarities score\n",
    "    \"\"\"\n",
    "    movie_index = None\n",
    "    movie_avg_desc_vector = None\n",
    "    cosine_similarities = None\n",
    "    ### Ex-5-Task-1\n",
    "    ### BEGIN SOLUTION \n",
    "    movie_index = df[df['title'] == movie].index[0]\n",
    "    \n",
    "    movie_avg_desc_vector = df.loc[movie_index, 'avg_description_vector'].reshape(1, -1)\n",
    "    \n",
    "    all_vectors = np.stack(df['avg_description_vector'].values)\n",
    "     \n",
    "    cosine_similarities = cosine_similarity(movie_avg_desc_vector, all_vectors)[0]\n",
    "    \n",
    "    similarity_list = list(zip(df['title'], cosine_similarities))\n",
    "    similarity_list = sorted(similarity_list, key=lambda x: x[1], reverse=True)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "68pe5iXtvzqR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "928552072470ca9d9499471e9fdfe7a5",
     "grade": true,
     "grade_id": "cell-8a79d6f605c196e4",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-5-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNzm3b2GvzqR"
   },
   "source": [
    "### Exercise 6: Movie Recommendation\n",
    "<b><div style=\"text-align: right\">[POINTS: 2]</div></b>\n",
    "\n",
    "\n",
    "Now, your task is to recommend top 5 similar movies based on the cosine similary scores between the averaged description vector of the given movie and all of the averaged description vectors.\n",
    "\n",
    "**Tasks:**\n",
    "* cosine_similarities: cosine similarities between description vector of the movie and all of the descriptions (vectors) of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "id": "weVBm1K4vzqR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f330f0555117aa224831e78a301b743e",
     "grade": false,
     "grade_id": "cell-4cccc161f0b4164e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "Ex-6-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "def recommendations(movie, df=df):\n",
    "    \"\"\"\n",
    "    Recommending the top 5 similar movies\n",
    "\n",
    "    Args:\n",
    "        movie (str): Title of the Movie\n",
    "        df (DataFrame): DataFrame containing Movie title and Movie Description\n",
    "    Returns:\n",
    "        list: list of top 5 similar Movie title with their cosine similarities score\n",
    "    \"\"\"\n",
    "    \n",
    "    cosine_similarities = None\n",
    "    ### Ex-6-Task-1\n",
    "    ### BEGIN SOLUTION \n",
    "    movie_index = df[df['title'] == movie].index[0]\n",
    "    \n",
    "    movie_avg_desc_vector = df.loc[movie_index, 'avg_description_vector'].reshape(1, -1)\n",
    "    \n",
    "    all_vectors = np.stack(df['avg_description_vector'].values)\n",
    "    \n",
    "    cosine_similarities = cosine_similarity(movie_avg_desc_vector, all_vectors)\n",
    "    ### END SOLUTION\n",
    "    similarities_scores = list(enumerate(cosine_similarities.squeeze().tolist()))  # index and vector values of cosine similarities\n",
    "    sorted_similarities_scores = sorted(similarities_scores, key = lambda x: x[1], reverse = True) # sorted in descending order of index and vector values of cosine similarities\n",
    "    top5_sim_scores = sorted_similarities_scores[1:6]  # top 5 indices and similarity scores\n",
    "    top5_movie_indices = [index for index, score in top5_sim_scores] # top 5 movie indices\n",
    "    top5_movie_scores = [score for index, score in top5_sim_scores] # top 5 movie scores\n",
    "    top5_movie_titles = df.iloc[top5_movie_indices]['title'].tolist() # top 5 movie titles\n",
    "    \n",
    "    return list(zip(top5_movie_titles, top5_movie_scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_ijumWPivzqS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8912447d5b8c5b0eca9f8cddcf25b156",
     "grade": true,
     "grade_id": "cell-0e308d4f41412820",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "Ex-6-Task-1"
    ]
   },
   "outputs": [],
   "source": [
    "# Intentionally Left Blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZa1xkB4vzqS"
   },
   "source": [
    "Now that you have sucessfully created a recommendation for a movie, let's see some of the recommendation given by the model for test movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rb2NcD6P4tX_",
    "outputId": "ff86eb2a-6827-4b89-9ab0-fa3e4df8768b"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrecommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mToy Story\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mrecommendations\u001b[39m\u001b[34m(movie, df)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m### Ex-6-Task-1\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m### BEGIN SOLUTION \u001b[39;00m\n\u001b[32m     15\u001b[39m movie_index = df[df[\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m] == movie].index[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m movie_avg_desc_vector = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmovie_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mavg_description_vector\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m     19\u001b[39m all_vectors = np.stack(df[\u001b[33m'\u001b[39m\u001b[33mavg_description_vector\u001b[39m\u001b[33m'\u001b[39m].values)\n\u001b[32m     21\u001b[39m cosine_similarities = cosine_similarity(movie_avg_desc_vector, all_vectors)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "recommendations(\"Toy Story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxXkhs-i4tYC",
    "outputId": "d4a938c4-1513-4490-e83c-83e6438d0dbf"
   },
   "outputs": [],
   "source": [
    "recommendations(\"The Godfather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ho40Vlti4tYE",
    "outputId": "e44af7b1-ad22-4fe0-e4d8-48900aeb7606"
   },
   "outputs": [],
   "source": [
    "recommendations(\"Avatar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9zlGf3avzqS",
    "outputId": "e918cdbe-e734-410f-c4f7-00920a5bbde6"
   },
   "outputs": [],
   "source": [
    "recommendations(\"The Fault in Our Stars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNaBe2s3vzqS"
   },
   "source": [
    "Congratulations for sucessfully implementing a recommendation system using various NLP concepts!!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
